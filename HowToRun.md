# How To Run on Local Machine
Joshua (Chang Hyeon) Park | University of Chicago

This guide walks through running the full pipeline on a small example: from raw Sentinel-2 Level-2A data and ArcticDEM strips
to U-Net lake segmentation outputs.

## 1. Environment Setup:
Clone the repository and create a Python environment:
```commandline
git clone https://github.com/joshpark1007/SupraglacialLakeProject2025.git
cd SupraglacialLakeProject2025
```

Install dependencies (minimal version):
```commandline
# Option A: pip (simple)
python -m venv venv
source venv/bin/activate          # macOS / Linux
# .\venv\Scripts\activate         # Windows
pip install -r requirements.txt
```
Note: For geospatial libraries like `rasterio` and `geopandas`, using `conda`/`mamba` is recommended if you run into
installation issues.


## 2. Data Directory Layout:

The project expects the following directory structure under `data/`
![Data Architecture](images/supraglacial_dataarchitecture.png)

In text form:
```commandline
data/
  raw/
    SAFE/                           # Sentinel-2 .SAFE folders (user-provided)
      S2B_MSIL2A_20240803T151809_..._T22WDA_20240803T192030.SAFE
    ArcticDEM/                      # ArcticDEM downloads and VRT (generated)
      arcticdem_mosaic.vrt          # DEM mosaic (generated by build_vrt + fetch-dem.sh)
      tiles/                        # Extracted *_dem.tif strips (downloaded)
      dem_urls.txt                  # URL list (generated)
      dem_urls_raw.txt
      dem_urls_2m.txt
      dem_urls_10m.txt
      dem_urls.csv
      fetch-dem.sh                  # DEM downloader script (generated)

  indexes/
    ArcticDEM_Strip_Index_s2s041_shp/   # ArcticDEM strip index (user-provided)
      ArcticDEM_Strip_Index_s2s041.shp
      ArcticDEM_Strip_Index_s2s041.dbf
      ArcticDEM_Strip_Index_s2s041.prj
      ArcticDEM_Strip_Index_s2s041.shx

  derived/
    lakes/                        # NDWI, lake masks, aligned DEM, vectors (generated)
      dem_to_sentinel.tif
      dem_to_sentinel_clipped.tif
      2024-08-03_T22WDA_ndwi_0.25.tif
      2024-08-03_T22WDA_lake_ndwi0.25_dem0.tif
      2024-08-03_T22WDA_lakes.gpkg

  tiles/
    images/                       # NDWI tiles as .npz (generated)
    masks/                        # lake-mask tiles as .npz (generated)

```

## Run:

Main
"""
August 3rd, 2024 Tile T22WDA (Model Set-up)
python main.py process \
  --safe "data/raw/SAFE/S2B_MSIL2A_20240803T151809_N0511_R068_T22WDA_20240803T192030.SAFE" \
  --dem  "data/raw/ArcticDEM/arcticdem_mosaic.vrt" \
  --out  "data/derived/lakes" \
  --ndwi 0.25 \
  --emin 0 \
  --min-area-m2 1000 \
  --ext gpkg    
"""

Build VRT
Usage:

 python3 VRT/build_vrt.py \
  --index "data/indexes/ArcticDEM_Strip_Index_s2s041_shp/ArcticDEM_Strip_Index_s2s041.shp" \
  --out-dir "data/raw/ArcticDEM" \
  --sentinel-bounds 399960 7490220 509760 7600020 \
  --sentinel-crs EPSG:32622 \
  --buffer-m 1000 \
  --resolution 2m \
  --max-strips 5
 
make_tiles.py
Expected Script:
python make_tiles.py \
  --in-dir data/derived/lakes \
  --out-dir data/tiles \
  --tile-size 256 \
  --stride 128

What the script does:
- Searches for NDWI rasters named:
      <timestamp>_<tile>_ndwi_0.25.tif
- Finds the corresponding lake mask raster:
      <timestamp>_<tile>_lake_ndwi0.25_dem0.tif
- Ensures both rasters share identical grid shape + transform
- Slides a window across both rasters:
      window size = tile-size (default 256)
      step size   = stride (default 128)
- Saves each tile as a compressed .npz file:
      images/  → NDWI tiles (shape: 1 × H × W)
      masks/   → binary lake-mask tiles (shape: H × W)

Purpose: finding files like 2024-08-03_T22WDA_ndwi_0.25.tif, match with 2024-08-03_T22WDA_lake_ndwi0.25_dem0.tif
and cut them into aligned tiles for image segmentation modeling

Output:
Creates a dataset directory containing two subfolders:
    data/derived/tiles/images/
    data/derived/tiles/masks/
